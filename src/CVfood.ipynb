{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\user\\anaconda3\\lib\\site-packages (2.12.0)\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.13.0-cp39-cp39-win_amd64.whl (1.9 kB)\n",
      "Collecting tensorflow-intel==2.13.0 (from tensorflow)\n",
      "  Downloading tensorflow_intel-2.13.0-cp39-cp39-win_amd64.whl (276.5 MB)\n",
      "                                              0.0/276.5 MB ? eta -:--:--\n",
      "                                              0.1/276.5 MB 3.2 MB/s eta 0:01:27\n",
      "                                              0.3/276.5 MB 5.2 MB/s eta 0:00:54\n",
      "                                             1.2/276.5 MB 11.1 MB/s eta 0:00:25\n",
      "                                             2.5/276.5 MB 16.1 MB/s eta 0:00:18\n",
      "                                             2.9/276.5 MB 18.7 MB/s eta 0:00:15\n",
      "                                             5.4/276.5 MB 23.1 MB/s eta 0:00:12\n",
      "     -                                       8.1/276.5 MB 30.3 MB/s eta 0:00:09\n",
      "     -                                      10.5/276.5 MB 40.9 MB/s eta 0:00:07\n",
      "     -                                      13.0/276.5 MB 54.7 MB/s eta 0:00:05\n",
      "     --                                     15.9/276.5 MB 65.6 MB/s eta 0:00:04\n",
      "     --                                     18.3/276.5 MB 65.6 MB/s eta 0:00:04\n",
      "     --                                     20.6/276.5 MB 65.6 MB/s eta 0:00:04\n",
      "     ---                                    23.2/276.5 MB 65.6 MB/s eta 0:00:04\n",
      "     ---                                    26.0/276.5 MB 65.6 MB/s eta 0:00:04\n",
      "     ---                                    28.8/276.5 MB 65.6 MB/s eta 0:00:04\n",
      "     ----                                   31.3/276.5 MB 73.1 MB/s eta 0:00:04\n",
      "     ----                                   34.1/276.5 MB 65.6 MB/s eta 0:00:04\n",
      "     ----                                   35.8/276.5 MB 65.2 MB/s eta 0:00:04\n",
      "     -----                                  37.2/276.5 MB 59.5 MB/s eta 0:00:05\n",
      "     -----                                  39.2/276.5 MB 54.4 MB/s eta 0:00:05\n",
      "     -----                                  41.5/276.5 MB 50.1 MB/s eta 0:00:05\n",
      "     ------                                 44.3/276.5 MB 54.4 MB/s eta 0:00:05\n",
      "     ------                                 46.7/276.5 MB 54.4 MB/s eta 0:00:05\n",
      "     ------                                 49.4/276.5 MB 65.6 MB/s eta 0:00:04\n",
      "     -------                                51.9/276.5 MB 65.6 MB/s eta 0:00:04\n",
      "     -------                                54.2/276.5 MB 65.6 MB/s eta 0:00:04\n",
      "     -------                                57.5/276.5 MB 73.1 MB/s eta 0:00:03\n",
      "     --------                               60.2/276.5 MB 73.1 MB/s eta 0:00:03\n",
      "     --------                               62.9/276.5 MB 73.1 MB/s eta 0:00:03\n",
      "     ---------                              65.7/276.5 MB 73.1 MB/s eta 0:00:03\n",
      "     ---------                              68.1/276.5 MB 72.6 MB/s eta 0:00:03\n",
      "     ---------                              70.7/276.5 MB 65.6 MB/s eta 0:00:04\n",
      "     ----------                             72.8/276.5 MB 59.5 MB/s eta 0:00:04\n",
      "     ----------                             75.1/276.5 MB 59.5 MB/s eta 0:00:04\n",
      "     ----------                             77.0/276.5 MB 54.7 MB/s eta 0:00:04\n",
      "     ----------                             80.0/276.5 MB 59.5 MB/s eta 0:00:04\n",
      "     -----------                            82.8/276.5 MB 59.5 MB/s eta 0:00:04\n",
      "     -----------                            85.1/276.5 MB 65.6 MB/s eta 0:00:03\n",
      "     ------------                           87.8/276.5 MB 65.2 MB/s eta 0:00:03\n",
      "     ------------                           90.3/276.5 MB 72.6 MB/s eta 0:00:03\n",
      "     ------------                           92.7/276.5 MB 59.5 MB/s eta 0:00:04\n",
      "     -------------                          95.8/276.5 MB 72.6 MB/s eta 0:00:03\n",
      "     -------------                          98.8/276.5 MB 72.6 MB/s eta 0:00:03\n",
      "     -------------                         102.1/276.5 MB 72.6 MB/s eta 0:00:03\n",
      "     --------------                        105.0/276.5 MB 81.8 MB/s eta 0:00:03\n",
      "     --------------                        108.2/276.5 MB 72.6 MB/s eta 0:00:03\n",
      "     --------------                        111.2/276.5 MB 81.8 MB/s eta 0:00:03\n",
      "     ---------------                       112.6/276.5 MB 65.6 MB/s eta 0:00:03\n",
      "     ---------------                       115.3/276.5 MB 65.6 MB/s eta 0:00:03\n",
      "     ---------------                       118.0/276.5 MB 59.5 MB/s eta 0:00:03\n",
      "     ----------------                      120.7/276.5 MB 65.6 MB/s eta 0:00:03\n",
      "     ----------------                      122.9/276.5 MB 65.6 MB/s eta 0:00:03\n",
      "     ----------------                      125.7/276.5 MB 72.6 MB/s eta 0:00:03\n",
      "     -----------------                     128.0/276.5 MB 65.6 MB/s eta 0:00:03\n",
      "     -----------------                     130.0/276.5 MB 59.5 MB/s eta 0:00:03\n",
      "     -----------------                     132.2/276.5 MB 59.5 MB/s eta 0:00:03\n",
      "     ------------------                    134.7/276.5 MB 59.5 MB/s eta 0:00:03\n",
      "     ------------------                    137.6/276.5 MB 59.5 MB/s eta 0:00:03\n",
      "     ------------------                    140.4/276.5 MB 72.6 MB/s eta 0:00:02\n",
      "     -------------------                   143.1/276.5 MB 72.6 MB/s eta 0:00:02\n",
      "     -------------------                   146.5/276.5 MB 81.8 MB/s eta 0:00:02\n",
      "     --------------------                  149.6/276.5 MB 81.8 MB/s eta 0:00:02\n",
      "     --------------------                  153.0/276.5 MB 93.9 MB/s eta 0:00:02\n",
      "     --------------------                  155.9/276.5 MB 81.8 MB/s eta 0:00:02\n",
      "     ---------------------                 158.3/276.5 MB 81.8 MB/s eta 0:00:02\n",
      "     ---------------------                 161.2/276.5 MB 73.1 MB/s eta 0:00:02\n",
      "     ---------------------                 163.9/276.5 MB 65.6 MB/s eta 0:00:02\n",
      "     ----------------------                166.8/276.5 MB 73.1 MB/s eta 0:00:02\n",
      "     ----------------------                169.5/276.5 MB 73.1 MB/s eta 0:00:02\n",
      "     ----------------------                171.6/276.5 MB 73.1 MB/s eta 0:00:02\n",
      "     -----------------------               174.4/276.5 MB 65.6 MB/s eta 0:00:02\n",
      "     -----------------------               176.8/276.5 MB 59.5 MB/s eta 0:00:02\n",
      "     ------------------------              179.5/276.5 MB 65.6 MB/s eta 0:00:02\n",
      "     ------------------------              182.3/276.5 MB 65.6 MB/s eta 0:00:02\n",
      "     ------------------------              184.8/276.5 MB 65.2 MB/s eta 0:00:02\n",
      "     -------------------------             187.6/276.5 MB 65.6 MB/s eta 0:00:02\n",
      "     -------------------------             190.1/276.5 MB 72.6 MB/s eta 0:00:02\n",
      "     -------------------------             193.0/276.5 MB 65.2 MB/s eta 0:00:02\n",
      "     --------------------------            195.3/276.5 MB 72.6 MB/s eta 0:00:02\n",
      "     --------------------------            197.3/276.5 MB 59.5 MB/s eta 0:00:02\n",
      "     --------------------------            199.7/276.5 MB 65.6 MB/s eta 0:00:02\n",
      "     --------------------------            201.2/276.5 MB 54.4 MB/s eta 0:00:02\n",
      "     ---------------------------           203.0/276.5 MB 46.7 MB/s eta 0:00:02\n",
      "     ---------------------------           204.9/276.5 MB 46.7 MB/s eta 0:00:02\n",
      "     ---------------------------           207.6/276.5 MB 50.4 MB/s eta 0:00:02\n",
      "     ----------------------------          210.6/276.5 MB 54.4 MB/s eta 0:00:02\n",
      "     ----------------------------          212.8/276.5 MB 59.5 MB/s eta 0:00:02\n",
      "     ----------------------------          215.7/276.5 MB 65.6 MB/s eta 0:00:01\n",
      "     -----------------------------         218.7/276.5 MB 65.2 MB/s eta 0:00:01\n",
      "     -----------------------------         221.8/276.5 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------        224.7/276.5 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------        227.3/276.5 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------        229.4/276.5 MB 65.6 MB/s eta 0:00:01\n",
      "     -------------------------------       232.3/276.5 MB 65.6 MB/s eta 0:00:01\n",
      "     -------------------------------       234.7/276.5 MB 65.6 MB/s eta 0:00:01\n",
      "     -------------------------------       237.0/276.5 MB 65.6 MB/s eta 0:00:01\n",
      "     --------------------------------      239.7/276.5 MB 65.6 MB/s eta 0:00:01\n",
      "     --------------------------------      242.2/276.5 MB 65.6 MB/s eta 0:00:01\n",
      "     --------------------------------      244.6/276.5 MB 59.5 MB/s eta 0:00:01\n",
      "     ---------------------------------     247.3/276.5 MB 65.6 MB/s eta 0:00:01\n",
      "     ---------------------------------     249.7/276.5 MB 59.8 MB/s eta 0:00:01\n",
      "     ---------------------------------     252.6/276.5 MB 65.6 MB/s eta 0:00:01\n",
      "     ----------------------------------    255.3/276.5 MB 65.6 MB/s eta 0:00:01\n",
      "     ----------------------------------    258.4/276.5 MB 73.1 MB/s eta 0:00:01\n",
      "     ----------------------------------    261.4/276.5 MB 73.1 MB/s eta 0:00:01\n",
      "     -----------------------------------   264.6/276.5 MB 81.8 MB/s eta 0:00:01\n",
      "     -----------------------------------   266.2/276.5 MB 72.6 MB/s eta 0:00:01\n",
      "     -----------------------------------   267.1/276.5 MB 59.5 MB/s eta 0:00:01\n",
      "     -----------------------------------   268.1/276.5 MB 50.1 MB/s eta 0:00:01\n",
      "     ------------------------------------  269.1/276.5 MB 43.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  271.0/276.5 MB 38.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  271.6/276.5 MB 34.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  273.2/276.5 MB 31.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  276.2/276.5 MB 31.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  276.5/276.5 MB 36.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  276.5/276.5 MB 36.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  276.5/276.5 MB 36.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  276.5/276.5 MB 36.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  276.5/276.5 MB 36.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  276.5/276.5 MB 36.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  276.5/276.5 MB 36.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  276.5/276.5 MB 36.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  276.5/276.5 MB 36.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  276.5/276.5 MB 36.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  276.5/276.5 MB 36.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  276.5/276.5 MB 36.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  276.5/276.5 MB 36.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  276.5/276.5 MB 36.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  276.5/276.5 MB 36.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  276.5/276.5 MB 36.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  276.5/276.5 MB 36.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  276.5/276.5 MB 36.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  276.5/276.5 MB 36.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  276.5/276.5 MB 36.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  276.5/276.5 MB 36.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  276.5/276.5 MB 36.4 MB/s eta 0:00:01\n",
      "     -------------------------------------- 276.5/276.5 MB 5.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (16.0.0)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.23.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.56.0)\n",
      "Collecting tensorboard<2.14,>=2.13 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "                                              0.0/5.6 MB ? eta -:--:--\n",
      "     ---------------                          2.1/5.6 MB 67.7 MB/s eta 0:00:01\n",
      "     ----------------------------             4.0/5.6 MB 51.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  5.6/5.6 MB 50.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 5.6/5.6 MB 39.4 MB/s eta 0:00:00\n",
      "Collecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
      "                                              0.0/440.8 kB ? eta -:--:--\n",
      "     ------------------------------------- 440.8/440.8 kB 28.7 MB/s eta 0:00:00\n",
      "Collecting keras<2.14,>=2.13.1 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
      "                                              0.0/1.7 MB ? eta -:--:--\n",
      "     ---------------------------------------  1.7/1.7 MB 112.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.7/1.7 MB 36.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.20.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.29.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.26.15)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (6.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2023.5.7)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.2)\n",
      "Installing collected packages: tensorflow-estimator, keras, tensorboard, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.12.0\n",
      "    Uninstalling tensorflow-estimator-2.12.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.12.0\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.12.0\n",
      "    Uninstalling keras-2.12.0:\n",
      "      Successfully uninstalled keras-2.12.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.12.3\n",
      "    Uninstalling tensorboard-2.12.3:\n",
      "      Successfully uninstalled tensorboard-2.12.3\n",
      "  Attempting uninstall: tensorflow-intel\n",
      "    Found existing installation: tensorflow-intel 2.12.0\n",
      "    Uninstalling tensorflow-intel-2.12.0:\n",
      "      Successfully uninstalled tensorflow-intel-2.12.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Accesso negato: 'C:\\\\Users\\\\USER\\\\anaconda3\\\\Lib\\\\site-packages\\\\~ensorflow\\\\compiler\\\\tf2tensorrt\\\\_pywrap_py_utils.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n",
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#%pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1477 files belonging to 20 classes.\n",
      "Using 1182 files for training.\n",
      "Nomi delle classi: ['Apple', 'Banana', 'Bread', 'Bun', 'Doughnut', 'Egg', 'Fired_dough', 'Grape', 'Lemon', 'Litchi', 'Mango', 'Mix', 'Mooncake', 'Orange', 'Peach', 'Pear', 'Plum', 'Qiwi', 'Sachima', 'Tomato']\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# Definizione dei parametri di caricamento delle immagini\n",
    "batch_size = 32\n",
    "image_size = (816, 612)\n",
    "directory = '../Dataset/JPEGImages/T'\n",
    "test_split = 0.2\n",
    "\n",
    "image_files = os.listdir(directory)\n",
    "# Caricamento delle immagini dalla directory\n",
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory,\n",
    "    class_names=None,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=test_split,\n",
    "    subset=\"training\",\n",
    "    seed=123\n",
    ")\n",
    "\n",
    "class_names = os.listdir(directory)\n",
    "print(\"Nomi delle classi:\", class_names)\n",
    "\n",
    "# Calcolo del numero di campioni per il set di test\n",
    "num_samples = train_dataset.cardinality().numpy()\n",
    "num_test_samples = int(num_samples * test_split)\n",
    "\n",
    "# Divisione del set di addestramento in set di addestramento e test\n",
    "test_dataset = train_dataset.take(num_test_samples)\n",
    "train_dataset = train_dataset.skip(num_test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow\n",
    "%pip install tf_slim\n",
    "%pip install tensorflow-hub\n",
    "%pip install tensorflow-object-detection-api\n",
    "%pip install tf-models-official\n",
    "%pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnimplementedError",
     "evalue": "File system scheme 'https' not implemented (file: 'https://tfhub.dev/tensorflow/faster_rcnn/resnet152_v1_1024x1024/inference/1/saved_model.pb')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m PATH_TO_LABELS \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m../Dataset/JPEGImages/T\u001b[39m\u001b[39m'\u001b[39m  \u001b[39m# Sostituisci con il percorso della mappa delle etichette\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[39m# Carica il modello pre-addestrato\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49msaved_model\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39mhttps://tfhub.dev/tensorflow/faster_rcnn/resnet152_v1_1024x1024/inference/1\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     16\u001b[0m \u001b[39m# Carica la mappa delle etichette\u001b[39;00m\n\u001b[0;32m     17\u001b[0m category_index \u001b[39m=\u001b[39m label_map_util\u001b[39m.\u001b[39mcreate_category_index_from_labelmap(PATH_TO_LABELS, use_display_name\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:858\u001b[0m, in \u001b[0;36mload\u001b[1;34m(export_dir, tags, options)\u001b[0m\n\u001b[0;32m    856\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(export_dir, os\u001b[39m.\u001b[39mPathLike):\n\u001b[0;32m    857\u001b[0m   export_dir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mfspath(export_dir)\n\u001b[1;32m--> 858\u001b[0m result \u001b[39m=\u001b[39m load_partial(export_dir, \u001b[39mNone\u001b[39;49;00m, tags, options)[\u001b[39m\"\u001b[39m\u001b[39mroot\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    859\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:963\u001b[0m, in \u001b[0;36mload_partial\u001b[1;34m(export_dir, filters, tags, options)\u001b[0m\n\u001b[0;32m    958\u001b[0m \u001b[39mif\u001b[39;00m tags \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(tags, \u001b[39mset\u001b[39m):\n\u001b[0;32m    959\u001b[0m   \u001b[39m# Supports e.g. tags=SERVING and tags=[SERVING]. Sets aren't considered\u001b[39;00m\n\u001b[0;32m    960\u001b[0m   \u001b[39m# sequences for nest.flatten, so we put those through as-is.\u001b[39;00m\n\u001b[0;32m    961\u001b[0m   tags \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mflatten(tags)\n\u001b[0;32m    962\u001b[0m saved_model_proto, debug_info \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 963\u001b[0m     loader_impl\u001b[39m.\u001b[39;49mparse_saved_model_with_debug_info(export_dir))\n\u001b[0;32m    965\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mlen\u001b[39m(saved_model_proto\u001b[39m.\u001b[39mmeta_graphs) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m\n\u001b[0;32m    966\u001b[0m     saved_model_proto\u001b[39m.\u001b[39mmeta_graphs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mHasField(\u001b[39m\"\u001b[39m\u001b[39mobject_graph_def\u001b[39m\u001b[39m\"\u001b[39m)):\n\u001b[0;32m    967\u001b[0m   metrics\u001b[39m.\u001b[39mIncrementReadApi(_LOAD_V2_LABEL)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py:58\u001b[0m, in \u001b[0;36mparse_saved_model_with_debug_info\u001b[1;34m(export_dir)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparse_saved_model_with_debug_info\u001b[39m(export_dir):\n\u001b[0;32m     46\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Reads the savedmodel as well as the graph debug info.\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \n\u001b[0;32m     48\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[39m    parsed. Missing graph debug info file is fine.\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m   saved_model \u001b[39m=\u001b[39m parse_saved_model(export_dir)\n\u001b[0;32m     60\u001b[0m   debug_info_path \u001b[39m=\u001b[39m file_io\u001b[39m.\u001b[39mjoin(\n\u001b[0;32m     61\u001b[0m       path_helpers\u001b[39m.\u001b[39mget_debug_dir(export_dir),\n\u001b[0;32m     62\u001b[0m       constants\u001b[39m.\u001b[39mDEBUG_INFO_FILENAME_PB)\n\u001b[0;32m     63\u001b[0m   debug_info \u001b[39m=\u001b[39m graph_debug_info_pb2\u001b[39m.\u001b[39mGraphDebugInfo()\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py:99\u001b[0m, in \u001b[0;36mparse_saved_model\u001b[1;34m(export_dir)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[39m# Parse the SavedModel protocol buffer.\u001b[39;00m\n\u001b[0;32m     98\u001b[0m saved_model \u001b[39m=\u001b[39m saved_model_pb2\u001b[39m.\u001b[39mSavedModel()\n\u001b[1;32m---> 99\u001b[0m \u001b[39mif\u001b[39;00m file_io\u001b[39m.\u001b[39;49mfile_exists(path_to_pb):\n\u001b[0;32m    100\u001b[0m   \u001b[39mwith\u001b[39;00m file_io\u001b[39m.\u001b[39mFileIO(path_to_pb, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m    101\u001b[0m     file_content \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mread()\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py:298\u001b[0m, in \u001b[0;36mfile_exists\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[39m@tf_export\u001b[39m(v1\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mgfile.Exists\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m    297\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfile_exists\u001b[39m(filename):\n\u001b[1;32m--> 298\u001b[0m   \u001b[39mreturn\u001b[39;00m file_exists_v2(filename)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py:290\u001b[0m, in \u001b[0;36mfile_exists_v2\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Determines whether a path exists or not.\u001b[39;00m\n\u001b[0;32m    252\u001b[0m \n\u001b[0;32m    253\u001b[0m \u001b[39m>>> with open(\"/tmp/x\", \"w\") as f:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[39m  errors.OpError: Propagates any errors reported by the FileSystem API.\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 290\u001b[0m   _pywrap_file_io\u001b[39m.\u001b[39;49mFileExists(compat\u001b[39m.\u001b[39;49mpath_to_bytes(path))\n\u001b[0;32m    291\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mNotFoundError:\n\u001b[0;32m    292\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mUnimplementedError\u001b[0m: File system scheme 'https' not implemented (file: 'https://tfhub.dev/tensorflow/faster_rcnn/resnet152_v1_1024x1024/inference/1/saved_model.pb')"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "\n",
    "# Percorso al modello pre-addestrato\n",
    "PATH_TO_SAVED_MODEL = '../Preprocessed/faster_rcnn_resnet152_v1_1024x1024_coco17_tpu-8.config'  # Sostituisci con il percorso del modello pre-addestrato\n",
    "\n",
    "# Percorso alla mappa delle etichette\n",
    "PATH_TO_LABELS = '../Dataset/JPEGImages/T'  # Sostituisci con il percorso della mappa delle etichette\n",
    "\n",
    "# Carica il modello pre-addestrato\n",
    "model = tf.saved_model.load()\n",
    "\n",
    "# Carica la mappa delle etichette\n",
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)\n",
    "\n",
    "# Effettua il rilevamento oggetti\n",
    "detections = model(PATH_TO_LABELS)\n",
    "\n",
    "# Visualizza i risultati del rilevamento\n",
    "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "    image_np,\n",
    "    detections['detection_boxes'][0].numpy(),\n",
    "    (detections['detection_classes'][0].numpy() + 1).astype(int),\n",
    "    detections['detection_scores'][0].numpy(),\n",
    "    category_index,\n",
    "    use_normalized_coordinates=True,\n",
    "    max_boxes_to_draw=200,\n",
    "    min_score_thresh=0.3,\n",
    "    agnostic_mode=False\n",
    ")\n",
    "\n",
    "# Mostra l'immagine con le detection\n",
    "image_np = cv2.imread(image_path)\n",
    "image_np = cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB)\n",
    "cv2.imshow('Object Detection', image_np)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1477 images belonging to 20 classes.\n",
      "Epoch 1/10\n",
      "24/24 [==============================] - ETA: 0s - loss: 11.3596 - accuracy: 0.6249WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "24/24 [==============================] - 131s 5s/step - loss: 11.3596 - accuracy: 0.6249\n",
      "Epoch 2/10\n",
      "18/24 [=====================>........] - ETA: 34s - loss: 1.4946 - accuracy: 0.9201"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 48\u001b[0m\n\u001b[0;32m     45\u001b[0m early_stopping \u001b[39m=\u001b[39m EarlyStopping(patience\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, restore_best_weights\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m     47\u001b[0m \u001b[39m# Addestramento del modello con Early Stopping\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m model\u001b[39m.\u001b[39;49mfit(train_dataset, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m,  callbacks\u001b[39m=\u001b[39;49m[early_stopping])\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1734\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1735\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1736\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1739\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1740\u001b[0m ):\n\u001b[0;32m   1741\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1742\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1743\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1744\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    854\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    855\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    856\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_no_variable_creation_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    859\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    860\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m    147\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1346\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1347\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1348\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function(\u001b[39m*\u001b[39;49margs))\n\u001b[0;32m   1350\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m     args,\n\u001b[0;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1353\u001b[0m     executing_eagerly)\n\u001b[0;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[0;32m    195\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 196\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    197\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[0;32m    198\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[0;32m    199\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[0;32m    200\u001b[0m     )\n\u001b[0;32m    201\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\u001b[39mself\u001b[39m, \u001b[39mlist\u001b[39m(args))\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[0;32m   1456\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m   1458\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1459\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[0;32m   1460\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[0;32m   1461\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m   1462\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1463\u001b[0m   )\n\u001b[0;32m   1464\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1466\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m   1467\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1471\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[0;32m   1472\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Dimensioni delle immagini per ResNet50 (224x224)\n",
    "input_shape = (224, 224, 3)\n",
    "\n",
    "# Numero di classi del tuo problema di classificazione\n",
    "num_classes = 20  # Assumi che ci siano 10 classi, sostituisci con il tuo numero reale\n",
    "\n",
    "# Preprocessamento delle immagini\n",
    "preprocess_input = tf.keras.applications.resnet50.preprocess_input\n",
    "\n",
    "# Creazione del modello R-CNN\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=Input(shape=input_shape))\n",
    "base_model.trainable = False\n",
    "\n",
    "input_layer = Input(shape=input_shape)\n",
    "preprocessed_input = preprocess_input(input_layer)\n",
    "\n",
    "rcnn_features = base_model(preprocessed_input)\n",
    "flatten_features = tf.keras.layers.Flatten()(rcnn_features)\n",
    "output_layer = tf.keras.layers.Dense(num_classes, activation='softmax')(flatten_features)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compilazione del modello\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Utilizza ImageDataGenerator per caricare le immagini dal percorso specificato\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "train_dataset = datagen.flow_from_directory(\n",
    "    directory,\n",
    "    target_size=input_shape[:2],  \n",
    "    batch_size=64,           \n",
    "    class_mode='sparse'\n",
    ")\n",
    "\n",
    "# Callback di Early Stopping\n",
    "early_stopping = EarlyStopping(patience=3, restore_best_weights=False)\n",
    "\n",
    "# Addestramento del modello con Early Stopping\n",
    "model.fit(train_dataset, epochs=10, batch_size=64,  callbacks=[early_stopping])\n",
    "\n",
    "# Addestramento del modello\n",
    "#model.fit(train_dataset,epochs=5, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_dataset)\n",
    "y_true = test_dataset.classes\n",
    "y_pred = tf.argmax(predictions, axis=1)\n",
    "\n",
    "# Calcolo delle metriche\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "recall = recall_score(y_true, y_pred, average='macro')\n",
    "precision = precision_score(y_true, y_pred, average='macro')\n",
    "\n",
    "# Stampa delle metriche\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Precision:\", precision)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
